<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">

<head>
  <title>Hshmat Sahak</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <link rel="stylesheet" href="styles.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>
</head>

<body>

<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-dark navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                      <span class="sr-only">Toggle navigation</span>
                      <span class="icon-bar"></span>
                      <span class="icon-bar"></span>
                      <span class="icon-bar"></span>
        </button>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav navbar-right">
            <li class="nav-item"><a href="#about">About</a></li>
            <li class="nav-item"><a href="#education">Education</a></li>
            <li class="nav-item"><a href="#experience">Experience</a></li>
            <li class="nav-item"><a href="#publications">Publications</a></li> 
            <li class="nav-item"><a href="#projects">Projects</a></li>
            <li class="nav-item"><a href="Curriculum_Vitae.pdf" download="Hshmat_Sahak_CV">CV</a></li> 
        </ul>
      </div>
    </div>
</nav>
  
<!-- Page Content -->
<div class="container">

    <div>
        <div class="panel">
            <!--About-->
            <h1 id="about">Hshmat Sahak</h1>     
            <img class="img-responsive" src="imgs/me.png" alt="" class="headshot"><br>       
            <p>I am a 4th year Engineering Science student at the University of Toronto, pursuing a major in Machine Learning and minor in Robotics
                and Mechatronics. I have previously worked at <a href="https://research.google/teams/brain" target="_blank" rel="noopener noreferrer">Google Brain</a> (Student Researcher), 
                <a href="https://www.tesla.com/" target="_blank" rel="noopener noreferrer">Tesla</a> (Software Automation Engineer Intern) and <a href="https://www.nvidia.com/en-us/" target="_blank" rel="noopener noreferrer">Nvidia</a> 
                (Deep Learning Intern). I have completed research internships at the <a href="https://vectorinstitute.ai/" target="_blank" rel="noopener noreferrer">Vector Institute</a> for AI 
                (advised by <a href="https://jimmylba.github.io/" target="_blank" rel="noopener noreferrer">Prof. Jimmy Ba</a>), <a href="https://d3m.mie.utoronto.ca/" target="_blank" rel="noopener noreferrer">Data-Driven Decision-Making 
                Lab</a> (advised by <a href="https://www.mie.utoronto.ca/faculty_staff/sanner/" target="_blank" rel="noopener noreferrer">Prof. Scott Sanner</a>) and the <a href="Dynamic Systems Lab" target="_blank" rel="noopener noreferrer">
                Dynamic Systems Lab</a> (advised by <a href="https://www.dynsyslab.org/prof-angela-schoellig/" target="_blank" rel="noopener noreferrer">Prof. Angela Schoellig</a>). I am currently 
                working on my Bachelor Thesis project under <a href="http://asrl.utias.utoronto.ca/~tdb/" target="_blank" rel="noopener noreferrer">Prof. Tim Barfoot</a>, where I tackle the problem
                of indoor navigation of robots in cluttered environments. My plan is to pursue a PhD in the intersection of Machine Learning and Robotics.
            </p>
            
            <p>My research interests include:
                <ul>
                    <li>Robot Perception - 3D Object Detection and Semantic Segmentation for Scene Understanding</li>
                    <li>Autonomous Path Planning for Indoor and Outdoor Navigation of Robots</li>
                    <li>Developing efficient learning algorithms for function optimization in Deep Neural Networks</li>
                    <li>Generative AI for Image-to-Image and Discriminative tasks- e.g., Diffusion Models, GANs, NeRF Models</li>
                    <li>Broadly interested in Reinforcement Learning and NLP</li>
                    <li>Broadly interested in Computer Networks and Distributed Systems</li>
                </ul>
            </p>

            <p>
                If you are a current Graduate student in Machine Learning, Robotics, or at the intersection, I would love to hear about your work!
                If you are an incoming Engineering Science student, feel free to connect to ask questions about the program. You can reach me at 
                <a href="mailto:hshmat.sahak@mail.utoronto.ca" target="_blank" rel="noopener noreferrer">hshmat.sahak@mail.utoronto.ca</a>
            </p>

            <!-- <p><b>hshmat.sahak@mail.utoronto.ca</b><br>
            <p>University of Toronto<br>
            Undergraduate, 4th year<br>
            Major: Machine Learning<br>
            Minor: Robotics and Mechatronics <br>
            </p> -->
        </div>
        
        <!-- Links on the Sidebar -->
        <div class="panel" style="text-align: center;">
            <a href="https://arxiv.org/search/cs?searchtype=author&query=Sahak%2C+H" target="_blank" rel="noopener noreferrer">Google Scholar</a> / <a href="https://twitter.com/HshmatSahak" target="_blank" rel="noopener noreferrer">Twitter</a> / <a href="https://www.linkedin.com/in/hshmat-sahak-08314b1b5" target="_blank" rel="noopener noreferrer">LinkedIn</a> / <a href="https://github.com/hshmatsahak" target="_blank" rel="noopener noreferrer">Github</a>
        </div>
    </div>
        
    <div>
        <div class="panel">
            <h2 id="education">Education</h2><br>
            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/uoft_logo.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>University of Toronto</b><br><br>
                        <a href="https://engsci.utoronto.ca/program/what-is-engsci/" target="_blank" rel="noopener noreferrer" style="color: green">BASc. in Engineering Science</a> | 2019-2024<br>
                        <b>Machine Learning Major, Robotics and Mechatronics Minor (cGPA: 3.99/4.00)</b><br>
                        <b>Relevant Courses:</b> Machine Learning, Robot Modelling and Control, Artificial Intelligence, Control Theory, 
                        Systems Software, Computing, Probabilistic Reasoning, Distributed Systems
                    </p>
                </div>
            </div>
        </div>

        <!--Work Experience-->
        <div class="panel">
            <h2 id="experience">Work Experience</h2><br>
            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/tesla_logo.jpeg" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Software Automation Engineer Intern</b><br>
                        <a href="https://www.tesla.com/" target="_blank" rel="noopener noreferrer" style="color: green">Tesla</a><br>
                        <i>May 2023 - Aug 2023 <span>&#183;</span> Fremont, CA, USA</i><br>
                        Worked on Root Cause Analysis in the Cell Manufacturing Pipeline, and real-time Monitoring of Systems. Gained
                        familiarity with Prometheus, Grafana, InfluxDB, GoLang, React, Docker and Kubernetes. Applied ML and statistical 
                        techniques to anomaly detection and time series forecasting.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/vector_logo.jpeg" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Research Intern</b><br>
                        <a href="https://vectorinstitute.ai/" target="_blank" rel="noopener noreferrer" style="color: green">Vector Institute</a><br>
                        <i>Jan 2023 - May 2023 <span>&#183;</span> Toronto, ON, CA</i><br>
                        Worked on using Generative AI, specifically Diffusion Models, to improve performance of discriminative models by training on 
                        real and synthetic images, instead of just the original dataset. Identified 3 key requirements in order for diffusion-based 
                        foundation models to outperform original datasets in downstream classification.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/google_logo.jpeg" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Student Researcher</b><br>
                        <a href="https://research.google/teams/brain/" target="_blank" rel="noopener noreferrer" style="color: green">Google Brain</a><br>
                        <i>May 2022 - Dec 2022 <span>&#183;</span> Toronto, ON, CA</i><br>
                        Implemented Denoising Diffusion Probabilistic Models for Robust Super-Resolution (SR) in the wild. My work resulted in a patented
                        publication. The proposed model, SR3+, is an improvement over SR3 and can be used for photorealistic 4x SR even when
                        trained on out-of-distribution datasets, and can be cascaded for 16x SR.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/uoft_logo.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Research Intern</b><br>
                        <a href="https://torontoheartcentre.ca/doctors/dr-paul-dorian/" target="_blank" rel="noopener noreferrer" style="color: green">University of Toronto, Division of Cardiology</a><br>
                        <i>Sep 2021 - Apr 2022 <span>&#183;</span> Toronto, ON, CA <span>&#183;</span> Part-Time</i><br>
                        I was the Lead Data Scientist in the Toronto Cardiology Team. I worked alongside a team of doctors; we co-authored 2 papers- 
                        both submitted to The 2022 Canadian Cardiovascular Congress. The project was to determine how patient-reported 
                        breathlessness correlates with several objective measures of respiration.  I analyzed data collected from exercise 
                        stress tests and produced visualizations using Python, MATLAB and Jupyter Notebook.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/nvidia_logo.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Deep Learning for Power Architecture Intern</b><br>
                        <a href="https://www.nvidia.com/" target="_blank" rel="noopener noreferrer" style="color: green">Nvidia</a><br>
                        <i>May 2021 - Aug 2021 <span>&#183;</span> Santa Clara, CA, USA</i><br>
                        Worked on project using state-of-the-art machine learning techniques to enhance dynamic boost feature for next generation of 
                        Nvidia's GPU. Implemented algorithm to improve battery-mode dynamic compute power predictions by considering GPU idle time.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/uoft_logo.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Research Intern</b><br>
                        <a href="https://d3m.mie.utoronto.ca/" target="_blank" rel="noopener noreferrer" style="color: green">University of Toronto, Data-Driven Decision-Making Lab</a><br>
                        <i>May 2021 - Aug 2021 <span>&#183;</span> Santa Clara, CA, USA <span>&#183;</span> Part-Time</i><br>
                        Investigated whether Twitter data was an appropriate indicator of the spread of Covid-19 across Canada and USA. I fine-tuned a 
                        BERT model (ML model for NLP) using PyTorch to detect mask sentiments, resulting in a 41% improvement in mask attitude classification 
                        compared to vanilla VADER sentiment analysis, outperforming existing hashtag and regex-based classifiers
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/dsl_logo.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Research Intern</b><br>
                        <a href="https://www.dynsyslab.org/vision-news/" target="_blank" rel="noopener noreferrer" style="color: green">University of Toronto, Dynamic Systems Lab</a><br>
                        <i>May 2020 - Aug 2020 <span>&#183;</span> Santa Clara, CA, USA <span>&#183;</span> Part-Time</i><br>
                        Designed and implement a scalable, real time trajectory generation algorithm using MATLAB to synchronize the flight of 50 drones
                        with live music from a MIDI keyboard. I also surveyed 20+ safe learning research papers and categorized them by key ML concepts
                        to aid in the creation of a safe learning survey paper.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/sunnybrook_logo.jpeg" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Software Intern</b><br>
                        <a href="https://sunnybrook.ca/research/content/?page=sri-groups-fus" target="_blank" rel="noopener noreferrer" style="color: green">Sunnybrook Research Institute</a><br>
                        <i>May 2020 - Aug 2020 <span>&#183;</span> Santa Clara, CA, USA <span>&#183;</span> Part-Time</i><br>
                        Part of the Focused Ultrasound High School Summer Research Program. I implemented an algorithm using Fast
                        Fourier transform to identify distribution of harmonics present in ultrasound-induced motion signals. I stored
                        lesion observations in a patient-to-observation database using SQL. I visualized lesion observations as a pseudo-colour, 
                        allowing for customizing colour pixel and bit representation using MATLAB.
                    </p>
                </div>
            </div><br>
        </div>        
                
        <!--Publications-->
        <div class="panel">    
            <h2 id="publications">Publications</h2>
            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/method.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;">
                        <strong style="color:blue;">Training on Thin Air: Improve Image Classification with Generated Data</strong><br>
                        <a href="https://www.linkedin.com/in/yongchao-zhou-a298a7158/?originalSubdomain=ca" target="_blank" rel="noopener noreferrer">Yongchao Zhou</a>, <strong>Hshmat Sahak</strong>, <a href="https://jimmylba.github.io/" target="_blank" rel="noopener noreferrer">Jimmy Ba</a><br>
                        <i>Preprint 2023</i><br>
                        <a style="color:purple" target="_blank" rel="noopener noreferrer">Project Page</a> / <a style="color:purple" target="_blank" rel="noopener noreferrer">Paper</a> / <a target="_blank" rel="noopener noreferrer" style="color:purple">Code</a> / <a target="_blank" rel="noopener noreferrer" style="color:purple">Slides</a><br><br>
                        We present Diffusion Inversion, a simple yet effective method that leverages the pre-trained generative model, Stable Diffusion,
                        to generate diverse, high-quality training data for image classification. Our approach captures the original data distribution
                        and ensures data coverage by inverting images to the latent space of Stable Diffusion, and generates diverse novel training images 
                        by conditioning the generative model on noisy versions of these vectors.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <!-- <img src="imgs/method.png" style="float: left; margin-right: 15px;" width="175" height="175"> -->
                    <video id="vid" width="100%" autoplay muted>
                        <source src="sr3p.mp4" type="video/mp4">
                    </video>
                    <script>
                        document.getElementById('vid').play();
                    </script>
                </div>
                <div class="description">
                    <p style="vertical-align:middle;">
                        <strong style="color:blue;">Denoising Diffusion Probabilistic Models for Robust Image Super-Resolution in the Wild</strong><br>
                        <strong>Hshmat Sahak</strong>, <a href="https://www.linkedin.com/in/danielwatson6/" target="_blank" rel="noopener noreferrer">Daniel Watson</a>, <a href="https://www.linkedin.com/in/chitwansaharia/?originalSubdomain=ca" target="_blank" rel="noopener noreferrer">Chitwan Saharia</a>, <a href="https://www.cs.toronto.edu/~fleet/" target="_blank" rel="noopener noreferrer">David Fleet</a><br>
                        <i>Preprint 2023</i><br>
                        <a href="https://arxiv.org/abs/2302.07864" target="_blank" rel="noopener noreferrer" style="color:purple">Paper</a><br><br>
                        This paper introduces SR3+, a diffusion-based model for blind super-resolution, establishing a new state-of-the-art. We advocate 
                        self-supervised training with a combination of composite, parameterized degradations for self-supervised training, and noise-conditioing 
                        augmentation during training and testing.
                    </p>
                </div>
            </div><br>
        </div>

        <!--Projects-->
        <div class="panel">
            <h2 id="projects">Projects</h2><br>
            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/method.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Diffusion Inversion: Steering Pre-Trained Diffusion Models to Improve Image Classification on Rare Datasets</b><br>
                        [Research Project] @ Vector Institute, with Yongchao Zhou and Jimmy Ba.<br><br>
                        We propose Diffusion Inversion, a simple yet effective method that utilizes pre-trained generative 
                        models to assist with discriminative learning, bridging the gap between real and synthetic data. 
                        Our method offers 2-3x sample complexity improvements and 6.5x reduction in sampling time.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/blueguardian.jpeg" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Blue Guardian: Protect Before they Connect</b><br>
                        [Research Project] @ Blue Guardian<br><br>
                        Blue Guardian is a startup that aims to revolutionize Youth Mental Health Detection through Sentiment Analysis of text messages.
                        I worked on implementing state-of-the-art NLP methods for emotion detection, including feature extraction and transformer architecture
                        implementation. I also tackled problems of limited and imbalanced datasets resulting from uncommon emotions. Our model has been deployed 
                        and can be accessed through the app or <a href="#" target="_blank" rel="noopener noreferrer">website</a>.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <!-- <img src="imgs/method.png" style="float: left; margin-right: 15px;" width="175" height="175"> -->
                    <video id="vid" width="100%" autoplay muted>
                        <source src="sr3p.mp4" type="video/mp4">
                    </video>
                    <script>
                        document.getElementById('vid').play();
                    </script>
                </div>
                <div class="description">
                    <p style="vertical-align:middle;">
                        <b>SR3+: Using DDPMs for Robust Super-Resolution in the Wild</b><br>
                        [Research Project] @ Google Brain, advised by David Fleet.<br><br>
                        We introduce SR3+, a diffusion model for blind image super-resolution, outperforming SR3 and the previous
                        SOTA on zero-shot RealSR and DRealSR benchmarks, across different model and training set sizes. Through a 
                        careful ablation study, we demonstrate the complementary benefits of parametric degradations and
                        noise conditioning augmentation techniques (with the latter also used at test time).
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/vghnet.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>VGH-Net: Predict Restaurant Ratings from Food Images using CNN</b><br>
                        [Final Project] @ University of Toronto, ECE324: Machine Learning, Software, and Neural Networks<br>
                        <a href="#" target="_blank" rel="noopener noreferrer">Final Report</a> / <a target="_blank" rel="noopener noreferrer">Code</a><br><br>
                        We present VGH-Net; a novel architecture for predicting restaurant ratings from a set of food images. VGH-Net training occurs 
                        in two stages. First, a CNN learns to predict image embeddings matching the output of BERT on a restaurant's text reviews. 
                        Then, it attaches a feed-forward neural network to predict the review-specific restaurant rating from the embedding.
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/praxis3.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Trash n' Track : Addressing Waste Management in Ghana</b><br>
                        [Final Project] @ University of Toronto, ESC204: Praxis III<br>
                        <a href="#" target="_blank" rel="noopener noreferrer">Final Report</a> / <a href="#" target="_blank" rel="noopener noreferrer">Slides</a><br><br>
                        Trash n' Track is a modular system that can be attached to existing waste bins to let waste collectors know of the location of full bins. It
                        uses an ultrasonic sensor to determine the available capacity of the waste bin. This information, along with the location of the waste 
                        bin determined from an onboard GPS module, is sent to a server using a LoRa transceiver. We have also created a webapp that connects to 
                        this backend in order to provide live updates of waste bin fullness and location to waste collectors.                            
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/d3m.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Using Twitter to detect the Spread of Covid-19</b><br>
                        [Research Project] @ University of Toronto, Data-Driven Decision-Making Lab<br>
                        <a href="#" target="_blank" rel="noopener noreferrer">Code</a> / <a href="#" target="_blank" rel="noopener noreferrer">Slides</a><br><br>
                        Compared COVID statistics in various regions with corresponding COVID-related tweet counts and mask/vaccine hesitancy scores. Used Folium library, 
                        word clouds and topic modelling to identify spatial & temporal tweet distribution. For more accurate labelling, fine-tuned BERT model using PyTorch 
                        to detect mask sentiments, improving mask attitude classification by 41% compared to vanilla VADER sentiment analysis and outperforming existing hashtag & regex-based classifiers                  
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/chessai.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Chess AI</b><br>
                        [Side Project], with Ritvik Singh<br>
                        <a href="#" target="_blank" rel="noopener noreferrer">Code</a><br><br>
                        Developed chess engine using Python chess module. Beta release used alpha-beta pruning on a minimax tree. Final version 
                        uses multiple advanced algorithms, including Killer Move Heuristic, History Heuristic, Principle Variation Search, Transposition Table, 
                        Zobrist Hashing, Quiescent Search, and Iterative Deepening. The AI is around 1500 ELO as measured by chess.com. 
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/snek.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Snake Game</b><br>
                        [Final Project] @ University of Toronto, ESC190: Data Structures and Algorithms<br>
                        <a href="#" target="_blank" rel="noopener noreferrer">Final Report</a> / <a href="#" target="_blank" rel="noopener noreferrer">Code</a><br><br>
                        Developed an AI agent to play the snake game. The agent starts at the top left and aims to consume all food while avoiding 
                        hitting the walls and itself as it grows. For small board sizes, used Randomized Path Finding Algorithm. For larger board sizes, 
                        used DFS on the game state stack to find the target. It is flexible across varying board sizes, while keeping O(n) 
                        space complexity on an nxn board. 
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/kohai.png" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>FRONT: Improved Can Openers at Kohai Life</b><br>
                        [Final Project] @ University of Toronto, ESC102: Praxis II, with Mingde Yin, Aoran Jiao, Ryan Ghosh<br>
                        <a href="#" target="_blank" rel="noopener noreferrer">Report</a> / <a href="#" target="_blank" rel="noopener noreferrer">Demo</a><br><br>
                        FRONT: Force Redirection Object Negotiator Tool, a retrofit extension designed to
                        be attached to the actuator bar of the handle of a can opener to allow opening of cans with less directed
                        work and make it easier for people of differing abilities to use in daily life. FRONT is a retrofit module
                        that aims to convert a simpler pulling force in any direction to the traditional rotary force needed to cut a
                        can. The nature of the design is intuitive; to cut the can one simply attaches the module and pulls on a
                        string attached to a rotary guide wheel, guaranteeing that there is some component of force in the
                        direction of undisturbed motion(useful work)           
                    </p>
                </div>
            </div><br>

            <div class="image_text">
                <div class="featured_image">
                    <img src="imgs/projects/robot.jpeg" style="width: 100%;">
                </div>
                <div class="description">
                    <p style="vertical-align:middle;"><b>Robot Pet</b><br>
                        [Side Project], with Gabriel Luo<br>
                        <a href="#" target="_blank" rel="noopener noreferrer">Code</a> / <a href="#" target="_blank" rel="noopener noreferrer">Demo</a><br><br>
                        Built and programmed a robotic pet that can pick up and sort objects, respond to stimuli, draw, and play the piano.
                        Worked with Arduino microcontroller; using Bluetooth to control the arm and various sensors for obstacle detection, path planning
                        and environmental detection.
                    </p>
                </div>
            </div><br>
        </div><br>
    </div>
</div>

<!--Interests/Hobbies-->
<!-- <div style="padding-bottom: 100px;" class="col-md-8 col-md-offset-2">
    <h2 style="text-align:center;">Interests/Hobbies</h2><br>
    <div class="gallery"> 
        <div class="gallery-item">
            <img class="gallery-image" src="imgs/hobbies/art.png"><br>
            <p style="text-align:center">I enjoy art (drawing and painting). As you can tell, I'm not very good at it. I also like playing basketball, which falls as art because it is poetry in motion.
            Most art I produce ends up being "abstract", but not intentionally.</p>
        </div>

        <div class="gallery-item">
            <img class="gallery-image" src="imgs/hobbies/chess.jpeg">
            <p style="text-align:center">I enjoy playing chess. I have participated in several team chess tournaments in high school, and have continued playing as a hobby through Undergrad.
            My peak rating was 1710. Access my chess.com profile <a href="https://www.chess.com/member/sickmanballer" target="_blank" rel="noopener noreferrer">here</a></p>
        </div>

        <div class="gallery-item">
            <img class="gallery-image" src="imgs/hobbies/rotary.jpeg"><br>
            <p style="text-align:center">I have received several scholarships for my volunteer work. I have volunteered at many sites since middle school (over 1000 recorded volunteer hours), including the 
                Retirement Center and Tutoring Program. </p>
        </div>
    </div>
</div> -->


</div>
    
</body>

</html>
